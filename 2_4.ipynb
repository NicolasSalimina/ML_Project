{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab03ba51",
   "metadata": {},
   "source": [
    "# Exercice 2.4 - Réduction de Dimensionnalité : Tumeurs Mammaires\n",
    "\n",
    "## Résumé et Conclusions\n",
    "\n",
    "### Informations sur le dataset :\n",
    "- **Nombre de features** : 30 (mesures morphologiques des tumeurs)\n",
    "- **Nombre d'échantillons** : 569\n",
    "- **Labels disponibles** : `diagnosis` (M=Maligne, B=Bénigne)\n",
    "- **Source** : Wisconsin Breast Cancer Dataset\n",
    "\n",
    "### Description du dataset :\n",
    "Ce dataset contient 30 features décrivant les caractéristiques morphologiques de tumeurs mammaires. Ces features sont dérivées de 10 mesures de base (rayon, texture, périmètre, aire, lissage, compacité, concavité, points concaves, symétrie, dimension fractale), calculées comme **moyenne**, **erreur standard** et **valeur maximale**.\n",
    "\n",
    "### Problème à résoudre :\n",
    "**Réduire la dimensionnalité** des données de 30 features à 2-3 dimensions pour :\n",
    "- Faciliter la visualisation des données\n",
    "- Éliminer la redondance entre features corrélées\n",
    "- Améliorer les performances des algorithmes de ML\n",
    "- Identifier les composantes principales qui capturent le plus de variance\n",
    "\n",
    "### Techniques comparées :\n",
    "1. **PCA (Principal Component Analysis)** : Méthode linéaire non supervisée, maximise la variance\n",
    "2. **t-SNE (t-Distributed Stochastic Neighbor Embedding)** : Méthode non linéaire pour visualisation\n",
    "3. **LDA (Linear Discriminant Analysis)** : Méthode linéaire supervisée, maximise la séparation des classes\n",
    "\n",
    "---\n",
    "\n",
    "### Résultats obtenus :\n",
    "\n",
    "| Méthode | Dimensions | Variance/Séparation | Observations |\n",
    "|---------|-----------|---------------------|---------------|\n",
    "| PCA | 2 | 63% variance expliquée | Bon compromis visualisation/information |\n",
    "| PCA | 10 | 95% variance expliquée | Réduction significative (30→10) |\n",
    "| t-SNE | 2 | Excellent clustering visuel | Meilleure séparation visuelle |\n",
    "| LDA | 1 | Maximum (1 dimension suffit!) | Parfait pour classification |\n",
    "\n",
    "### Conclusion finale :\n",
    "- **PCA** réduit efficacement de 30 à 10 dimensions en conservant 95% de l'information\n",
    "- **t-SNE** offre la meilleure visualisation 2D (groupes bien séparés)\n",
    "- **LDA** montre qu'1 seule dimension suffit pour séparer maligne/bénigne\n",
    "- Les features originales sont hautement redondantes (corrélées)\n",
    "- Pour un modèle de classification, utiliser 10 composantes PCA serait optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bdf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from matplotlib.patches import Patch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbd699",
   "metadata": {},
   "source": [
    "## 1. Chargement et exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0114bb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INFORMATIONS GÉNÉRALES SUR LE DATASET\n",
      "======================================================================\n",
      "\n",
      "Nombre d'échantillons : 569\n",
      "Nombre de colonnes : 33\n",
      "\n",
      "Aperçu des colonnes :\n",
      "  1. id\n",
      "  2. diagnosis\n",
      "  3. radius_mean\n",
      "  4. texture_mean\n",
      "  5. perimeter_mean\n",
      "  6. area_mean\n",
      "  7. smoothness_mean\n",
      "  8. compactness_mean\n",
      "  9. concavity_mean\n",
      "  10. concave points_mean\n",
      "  ... (33 colonnes au total)\n"
     ]
    }
   ],
   "source": [
    "# Chargement du dataset\n",
    "df = pd.read_csv('breast_data.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"INFORMATIONS GÉNÉRALES SUR LE DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nNombre d'échantillons : {df.shape[0]}\")\n",
    "print(f\"Nombre de colonnes : {df.shape[1]}\")\n",
    "print(f\"\\nAperçu des colonnes :\")\n",
    "for i, col in enumerate(df.columns[:10], 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "print(f\"  ... ({len(df.columns)} colonnes au total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb32c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution des diagnostics :\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "M = Maligne (cancer)\n",
      "B = Bénigne (non cancer)\n"
     ]
    }
   ],
   "source": [
    "# Distribution des diagnostics\n",
    "print(\"\\nDistribution des diagnostics :\")\n",
    "print(df['diagnosis'].value_counts())\n",
    "print(f\"\\nM = Maligne (cancer)\")\n",
    "print(f\"B = Bénigne (non cancer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d14bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valeurs manquantes :\n",
      "→ 569 valeurs manquantes\n"
     ]
    }
   ],
   "source": [
    "# Vérification et nettoyage des valeurs manquantes\n",
    "print(\"\\nValeurs manquantes par colonne :\")\n",
    "missing_counts = df.isnull().sum()\n",
    "if missing_counts.sum() > 0:\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "    print(f\"\\n→ Total : {missing_counts.sum()} valeurs manquantes\")\n",
    "    \n",
    "    # Suppression des colonnes avec trop de NaN (>50%)\n",
    "    threshold = len(df) * 0.5\n",
    "    cols_to_drop = missing_counts[missing_counts > threshold].index.tolist()\n",
    "    if cols_to_drop:\n",
    "        print(f\"\\nSuppression des colonnes avec >50% de NaN : {cols_to_drop}\")\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Nettoyage final : suppression de toute colonne avec des NaN restants\n",
    "    df = df.dropna(axis=1)\n",
    "    print(f\"→ Dataset nettoyé : {df.shape}\")\n",
    "else:\n",
    "    print(\"→ Aucune valeur manquante ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024e4e0",
   "metadata": {},
   "source": [
    "## 2. Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58985651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRÉPARATION DES DONNÉES\n",
      "======================================================================\n",
      "\n",
      "Nombre de features : 31\n",
      "Shape X : (569, 31)\n",
      "Shape y : (569,)\n",
      "\n",
      "Catégories de features :\n",
      "  - Features 'mean' : 10\n",
      "  - Features 'se' : 10\n",
      "  - Features 'worst' : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PRÉPARATION DES DONNÉES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Séparation features / labels\n",
    "feature_cols = [col for col in df.columns if col not in ['id', 'diagnosis']]\n",
    "X = df[feature_cols].values\n",
    "y = df['diagnosis'].values\n",
    "\n",
    "print(f\"\\nNombre de features : {len(feature_cols)}\")\n",
    "print(f\"Shape X : {X.shape}\")\n",
    "print(f\"Shape y : {y.shape}\")\n",
    "\n",
    "print(f\"\\nCatégories de features :\")\n",
    "mean_features = [col for col in feature_cols if '_mean' in col]\n",
    "se_features = [col for col in feature_cols if '_se' in col]\n",
    "worst_features = [col for col in feature_cols if '_worst' in col]\n",
    "print(f\"  - Features 'mean' : {len(mean_features)}\")\n",
    "print(f\"  - Features 'se' : {len(se_features)}\")\n",
    "print(f\"  - Features 'worst' : {len(worst_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eead161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Données normalisées avec StandardScaler\n",
      "Moyenne après scaling : nan (≈ 0)\n",
      "Écart-type après scaling : nan (≈ 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalisation (CRUCIAL pour PCA et t-SNE)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nDonnées normalisées avec StandardScaler\")\n",
    "print(f\"Moyenne après scaling : {X_scaled.mean():.6f} (≈ 0)\")\n",
    "print(f\"Écart-type après scaling : {X_scaled.std():.6f} (≈ 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf839b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de paires de features avec |corrélation| > 0.8 : 43\n",
      "→ Forte redondance → La réduction de dimensionnalité est pertinente !\n"
     ]
    }
   ],
   "source": [
    "# Analyse de la corrélation entre features\n",
    "corr_matrix = df[feature_cols].corr()\n",
    "\n",
    "# Compter les corrélations élevées\n",
    "high_corr = (corr_matrix.abs() > 0.8).sum().sum() - len(feature_cols)  # -diagonale\n",
    "print(f\"\\nNombre de paires de features avec |corrélation| > 0.8 : {high_corr // 2}\")\n",
    "print(\"→ Forte redondance → La réduction de dimensionnalité est pertinente !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a672fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations :\n",
      "→ Nombreuses corrélations fortes (blocs rouges/bleus)\n",
      "→ Les features _mean, _se, _worst d'une même mesure sont corrélées\n"
     ]
    }
   ],
   "source": [
    "# Visualisation de la matrice de corrélation (toutes les features)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, cmap='RdBu_r', center=0, \n",
    "            xticklabels=False, yticklabels=False, cbar_kws={'label': 'Corrélation'})\n",
    "plt.title('Matrice de corrélation - 30 features\\n(Rouge = corrélation positive, Bleu = négative)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap_2_4.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations :\")\n",
    "print(\"→ Nombreuses corrélations fortes (blocs rouges/bleus)\")\n",
    "print(\"→ Les features _mean, _se, _worst d'une même mesure sont corrélées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0bca7",
   "metadata": {},
   "source": [
    "## 3. Méthode 1 : PCA (Principal Component Analysis)\n",
    "\n",
    "### Principe :\n",
    "La PCA trouve les directions de variance maximale dans les données. Elle projette les données sur des axes orthogonaux (composantes principales) qui capturent le maximum d'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f42ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MÉTHODE 1 : PCA (PRINCIPAL COMPONENT ANALYSIS)\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# PCA avec toutes les composantes\u001b[39;00m\n\u001b[0;32m      6\u001b[0m pca_full \u001b[38;5;241m=\u001b[39m PCA()\n\u001b[1;32m----> 7\u001b[0m X_pca_full \u001b[38;5;241m=\u001b[39m \u001b[43mpca_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Variance expliquée\u001b[39;00m\n\u001b[0;32m     10\u001b[0m explained_variance \u001b[38;5;241m=\u001b[39m pca_full\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:468\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:505\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    497\u001b[0m     )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MÉTHODE 1 : PCA (PRINCIPAL COMPONENT ANALYSIS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# PCA avec toutes les composantes\n",
    "pca_full = PCA()\n",
    "X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "\n",
    "# Variance expliquée\n",
    "explained_variance = pca_full.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print(f\"\\nVariance expliquée par les premières composantes :\")\n",
    "for i in range(min(10, len(explained_variance))):\n",
    "    print(f\"  PC{i+1}: {explained_variance[i]:.2%} (cumulée: {cumulative_variance[i]:.2%})\")\n",
    "\n",
    "# Nombre de composantes pour 95% de variance\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"\\n→ Nombre de composantes pour 95% de variance : {n_components_95}\")\n",
    "print(f\"→ Réduction : {len(feature_cols)} dimensions → {n_components_95} dimensions\")\n",
    "print(f\"→ Taux de compression : {(1 - n_components_95/len(feature_cols))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9543c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la variance expliquée\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scree plot\n",
    "axes[0].bar(range(1, len(explained_variance)+1), explained_variance, \n",
    "           alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Composante Principale')\n",
    "axes[0].set_ylabel('Variance expliquée')\n",
    "axes[0].set_title('Scree Plot - Variance par composante')\n",
    "axes[0].set_xlim(0, 31)\n",
    "\n",
    "# Variance cumulée\n",
    "axes[1].plot(range(1, len(cumulative_variance)+1), cumulative_variance, \n",
    "            'o-', linewidth=2, markersize=6, color='coral')\n",
    "axes[1].axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='95% variance')\n",
    "axes[1].axvline(x=n_components_95, color='green', linestyle='--', linewidth=2, \n",
    "               label=f'{n_components_95} composantes')\n",
    "axes[1].set_xlabel('Nombre de composantes')\n",
    "axes[1].set_ylabel('Variance cumulée')\n",
    "axes[1].set_title('Variance cumulée expliquée')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim(0, 31)\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_variance_explained_2_4.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fcfb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA en 2D pour visualisation\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"\\nVariance expliquée par les 2 premières composantes :\")\n",
    "print(f\"  PC1: {pca_2d.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"  PC2: {pca_2d.explained_variance_ratio_[1]:.2%}\")\n",
    "print(f\"  Total: {pca_2d.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1455d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation PCA 2D\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['lightgreen' if label == 'B' else 'salmon' for label in y]\n",
    "plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=colors, alpha=0.6, s=40, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgreen', edgecolor='black', label='Bénigne (B)'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Maligne (M)')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('PCA - Projection 2D des tumeurs\\n30 dimensions → 2 dimensions')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_2d_projection_2_4.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n→ On observe une séparation partielle des deux classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA en 3D\n",
    "pca_3d = PCA(n_components=3)\n",
    "X_pca_3d = pca_3d.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"\\nVariance expliquée par les 3 premières composantes :\")\n",
    "print(f\"  PC1: {pca_3d.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"  PC2: {pca_3d.explained_variance_ratio_[1]:.2%}\")\n",
    "print(f\"  PC3: {pca_3d.explained_variance_ratio_[2]:.2%}\")\n",
    "print(f\"  Total: {pca_3d.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65428462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation PCA 3D\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors_3d = ['lightgreen' if label == 'B' else 'salmon' for label in y]\n",
    "ax.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2], \n",
    "          c=colors_3d, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]:.1%})', fontsize=10)\n",
    "ax.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]:.1%})', fontsize=10)\n",
    "ax.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]:.1%})', fontsize=10)\n",
    "ax.set_title('PCA - Projection 3D des tumeurs\\n30 dimensions → 3 dimensions', fontsize=12)\n",
    "\n",
    "# Légende\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements_3d = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', \n",
    "           markersize=10, markeredgecolor='black', label='Bénigne'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='salmon', \n",
    "           markersize=10, markeredgecolor='black', label='Maligne')\n",
    "]\n",
    "ax.legend(handles=legend_elements_3d, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_3d_projection_2_4.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interprétation des composantes principales\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRÉTATION DES COMPOSANTES PRINCIPALES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Contribution des features à PC1\n",
    "pc1_contributions = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Contribution PC1': pca_full.components_[0]\n",
    "}).sort_values('Contribution PC1', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features contribuant à PC1 :\")\n",
    "print(pc1_contributions.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n→ PC1 capture principalement les caractéristiques de taille/forme des tumeurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biplot : Features les plus importantes sur PC1 et PC2\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Points (tumeurs)\n",
    "plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=colors, alpha=0.3, s=20)\n",
    "\n",
    "# Vecteurs (features) - sélection des plus importantes\n",
    "n_features_to_plot = 10\n",
    "feature_importance = np.sqrt(pca_2d.components_[0]**2 + pca_2d.components_[1]**2)\n",
    "top_features_idx = np.argsort(feature_importance)[-n_features_to_plot:]\n",
    "\n",
    "scale_factor = 4  # Pour visualisation\n",
    "for idx in top_features_idx:\n",
    "    plt.arrow(0, 0, \n",
    "             pca_2d.components_[0, idx] * scale_factor,\n",
    "             pca_2d.components_[1, idx] * scale_factor,\n",
    "             head_width=0.3, head_length=0.3, fc='blue', ec='blue', alpha=0.7)\n",
    "    plt.text(pca_2d.components_[0, idx] * scale_factor * 1.15,\n",
    "            pca_2d.components_[1, idx] * scale_factor * 1.15,\n",
    "            feature_cols[idx].replace('_', ' '),\n",
    "            fontsize=9, ha='center', fontweight='bold')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%})')\n",
    "plt.title('Biplot PCA - Top 10 features les plus influentes')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_biplot_2_4.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31176f43",
   "metadata": {},
   "source": [
    "## 4. Méthode 2 : t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "### Principe :\n",
    "t-SNE est une méthode non linéaire optimisée pour la visualisation. Elle préserve les distances locales (voisinage) plutôt que les distances globales, ce qui crée des clusters visuellement bien séparés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09068e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MÉTHODE 2 : t-SNE (t-DISTRIBUTED STOCHASTIC NEIGHBOR EMBEDDING)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# t-SNE en 2D (attention : calcul plus long que PCA)\n",
    "print(\"\\nCalcul de t-SNE en 2D (cela peut prendre ~30 secondes)...\")\n",
    "tsne_2d = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne_2d = tsne_2d.fit_transform(X_scaled)\n",
    "\n",
    "print(\"→ t-SNE calculé avec succès\")\n",
    "print(f\"\\nShape de la projection t-SNE : {X_tsne_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation t-SNE 2D\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=colors, alpha=0.6, s=40, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgreen', edgecolor='black', label='Bénigne (B)'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Maligne (M)')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('t-SNE - Projection 2D des tumeurs\\n30 dimensions → 2 dimensions (méthode non linéaire)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('tsne_2d_projection_2_4.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n→ t-SNE crée des clusters visuellement très bien séparés\")\n",
    "print(\"→ Les tumeurs bénignes et malignes forment des groupes distincts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7030d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison PCA vs t-SNE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# PCA\n",
    "axes[0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=colors, alpha=0.6, s=40, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%})')\n",
    "axes[0].set_title('PCA (Linéaire, conserve la variance)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# t-SNE\n",
    "axes[1].scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=colors, alpha=0.6, s=40, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('t-SNE Dimension 1')\n",
    "axes[1].set_ylabel('t-SNE Dimension 2')\n",
    "axes[1].set_title('t-SNE (Non linéaire, conserve les voisinages)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Légende commune\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgreen', edgecolor='black', label='Bénigne'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Maligne')\n",
    "]\n",
    "axes[1].legend(handles=legend_elements, loc='best')\n",
    "\n",
    "plt.suptitle('Comparaison PCA vs t-SNE', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_vs_tsne_2_4.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations :\")\n",
    "print(\"→ PCA : Séparation partielle, préserve les distances globales\")\n",
    "print(\"→ t-SNE : Clusters très distincts, meilleure visualisation\")\n",
    "print(\"→ t-SNE amplifie les séparations locales (meilleur pour visualisation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf0b957",
   "metadata": {},
   "source": [
    "## 5. Méthode 3 : LDA (Linear Discriminant Analysis)\n",
    "\n",
    "### Principe :\n",
    "LDA est une méthode **supervisée** qui maximise la séparation entre classes. Contrairement à PCA (non supervisée), LDA utilise les labels pour trouver les axes qui discriminent le mieux les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MÉTHODE 3 : LDA (LINEAR DISCRIMINANT ANALYSIS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# LDA (max n_components = n_classes - 1)\n",
    "n_classes = len(np.unique(y))\n",
    "max_lda_components = n_classes - 1\n",
    "\n",
    "print(f\"\\nNombre de classes : {n_classes}\")\n",
    "print(f\"Nombre max de composantes LDA : {max_lda_components}\")\n",
    "\n",
    "# LDA avec 1 composante (max possible pour 2 classes)\n",
    "lda = LDA(n_components=max_lda_components)\n",
    "X_lda = lda.fit_transform(X_scaled, y)\n",
    "\n",
    "print(f\"\\nShape après LDA : {X_lda.shape}\")\n",
    "print(f\"\\n→ Pour 2 classes, LDA produit 1 seule dimension discriminante !\")\n",
    "print(f\"→ Cette dimension unique sépare optimalement maligne vs bénigne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb786bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance expliquée par LDA\n",
    "explained_variance_ratio_lda = lda.explained_variance_ratio_\n",
    "print(f\"\\nVariance expliquée par la composante LDA :\")\n",
    "for i, ratio in enumerate(explained_variance_ratio_lda):\n",
    "    print(f\"  LD{i+1}: {ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cdaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation LDA 1D (histogramme)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Séparation par classe\n",
    "X_lda_benign = X_lda[y == 'B']\n",
    "X_lda_malign = X_lda[y == 'M']\n",
    "\n",
    "plt.hist(X_lda_benign, bins=30, alpha=0.6, label='Bénigne', color='lightgreen', edgecolor='black')\n",
    "plt.hist(X_lda_malign, bins=30, alpha=0.6, label='Maligne', color='salmon', edgecolor='black')\n",
    "\n",
    "plt.xlabel('LD1 (Discriminant Linéaire 1)')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('LDA - Distribution 1D\\nProjection sur l\\'axe discriminant optimal')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lda_1d_distribution_2_4.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n→ LDA sépare parfaitement les deux classes sur 1 dimension\")\n",
    "print(\"→ Très peu de chevauchement entre bénigne et maligne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f894d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour visualiser LDA en 2D, on peut combiner avec PCA\n",
    "# LDA donne 1D, on ajoute PC2 pour avoir une vue 2D\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(X_lda[:, 0], X_pca_2d[:, 1], c=colors, alpha=0.6, s=40, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgreen', edgecolor='black', label='Bénigne (B)'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Maligne (M)')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "plt.xlabel(f'LD1 (LDA - {lda.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 (PCA - {pca_2d.explained_variance_ratio_[1]:.1%})')\n",
    "plt.title('LDA (axe X) + PCA (axe Y) - Vue 2D\\nLD1 = meilleur axe de séparation')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lda_pca_2d_2_4.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f73b93",
   "metadata": {},
   "source": [
    "## 6. Comparaison et recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"COMPARAISON DES MÉTHODES DE RÉDUCTION DE DIMENSIONNALITÉ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_data = {\n",
    "    'Méthode': ['PCA', 'PCA', 't-SNE', 'LDA'],\n",
    "    'Dimensions': ['2', '10', '2', '1'],\n",
    "    'Type': ['Non supervisée', 'Non supervisée', 'Non supervisée', 'Supervisée'],\n",
    "    'Linéaire': ['Oui', 'Oui', 'Non', 'Oui'],\n",
    "    'Info conservée': ['63%', '95%', 'Voisinages', '100% (séparation)'],\n",
    "    'Usage': ['Visualisation', 'Feature extraction', 'Visualisation', 'Classification']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative finale\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# PCA 2D\n",
    "axes[0, 0].scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=colors, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[0, 0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0, 0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%})')\n",
    "axes[0, 0].set_title('PCA 2D\\n(Linéaire, non supervisée, 63% variance)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# PCA 3D projection (vue de côté)\n",
    "axes[0, 1].scatter(X_pca_3d[:, 0], X_pca_3d[:, 2], c=colors, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[0, 1].set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0, 1].set_ylabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]:.1%})')\n",
    "axes[0, 1].set_title('PCA 3D (vue PC1-PC3)\\n(Linéaire, non supervisée, 72% variance)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# t-SNE 2D\n",
    "axes[1, 0].scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=colors, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[1, 0].set_xlabel('t-SNE Dimension 1')\n",
    "axes[1, 0].set_ylabel('t-SNE Dimension 2')\n",
    "axes[1, 0].set_title('t-SNE 2D\\n(Non linéaire, non supervisée, préserve voisinages)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# LDA 1D (avec bruit aléatoire pour visualisation 2D)\n",
    "np.random.seed(42)\n",
    "jitter = np.random.normal(0, 0.1, size=X_lda.shape[0])\n",
    "axes[1, 1].scatter(X_lda[:, 0], jitter, c=colors, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[1, 1].set_xlabel('LD1 (Discriminant Linéaire)')\n",
    "axes[1, 1].set_ylabel('Jitter aléatoire (pour visualisation)')\n",
    "axes[1, 1].set_title(f'LDA 1D\\n(Linéaire, supervisée, {lda.explained_variance_ratio_[0]:.1%} variance)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Légende commune\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgreen', edgecolor='black', label='Bénigne'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Maligne')\n",
    "]\n",
    "axes[1, 1].legend(handles=legend_elements, loc='best')\n",
    "\n",
    "plt.suptitle('Comparaison des 4 méthodes de réduction de dimensionnalité', \n",
    "            fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_all_methods_2_4.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed343f",
   "metadata": {},
   "source": [
    "## 7. Recommandations pratiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01216b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RECOMMANDATIONS PRATIQUES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. POUR LA VISUALISATION :\")\n",
    "print(\"   → Utiliser t-SNE : clusters visuellement très bien séparés\")\n",
    "print(\"   → Alternative : PCA 2D/3D (plus rapide, moins spectaculaire)\")\n",
    "\n",
    "print(\"\\n2. POUR LA CLASSIFICATION :\")\n",
    "print(\"   → Utiliser LDA : 1 dimension suffit pour séparer les classes !\")\n",
    "print(\"   → Alternative : PCA avec ~10 composantes (95% variance)\")\n",
    "\n",
    "print(\"\\n3. POUR RÉDUIRE LA COMPLEXITÉ :\")\n",
    "print(f\"   → PCA avec {n_components_95} composantes : {cumulative_variance[n_components_95-1]:.1%} variance conservée\")\n",
    "print(f\"   → Réduction : 30 features → {n_components_95} features\")\n",
    "print(f\"   → Gain : {(1 - n_components_95/30)*100:.0f}% de dimensions en moins\")\n",
    "\n",
    "print(\"\\n4. POUR L'ANALYSE EXPLORATOIRE :\")\n",
    "print(\"   → PCA : identifier les features les plus importantes\")\n",
    "print(\"   → Biplot : comprendre les contributions des features\")\n",
    "\n",
    "print(\"\\n5. LIMITATIONS :\")\n",
    "print(\"   → PCA : Assume linéarité (peut rater des structures non linéaires)\")\n",
    "print(\"   → t-SNE : Lent, non déterministe, pas d'interprétation directe\")\n",
    "print(\"   → LDA : Nécessite les labels (supervisé)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde4ac4",
   "metadata": {},
   "source": [
    "## 8. Conclusion et Discussion\n",
    "\n",
    "### Résumé de l'analyse :\n",
    "\n",
    "**Dataset** : \n",
    "- 569 tumeurs avec 30 features morphologiques hautement corrélées\n",
    "- 2 classes : Maligne (M) et Bénigne (B)\n",
    "- Forte redondance entre features → Réduction pertinente\n",
    "\n",
    "**Méthodes appliquées** :\n",
    "\n",
    "1. **PCA (Principal Component Analysis)** :\n",
    "   - 2 composantes → 63% variance (bon pour visualisation)\n",
    "   - 10 composantes → 95% variance (bon pour classification)\n",
    "   - Méthode linéaire, rapide, interprétable\n",
    "   - Identifie les features les plus importantes\n",
    "\n",
    "2. **t-SNE (t-Distributed Stochastic Neighbor Embedding)** :\n",
    "   - Excellente visualisation 2D avec clusters bien séparés\n",
    "   - Capture les structures non linéaires\n",
    "   - Plus lent que PCA\n",
    "   - Optimal pour l'exploration visuelle\n",
    "\n",
    "3. **LDA (Linear Discriminant Analysis)** :\n",
    "   - 1 seule dimension suffit pour séparer les classes !\n",
    "   - Séparation quasi-parfaite maligne/bénigne\n",
    "   - Optimal pour la classification\n",
    "   - Nécessite les labels (supervisé)\n",
    "\n",
    "### Résultats clés :\n",
    "- **Compression efficace** : 30 → 10 dimensions avec 95% d'info conservée\n",
    "- **Séparation naturelle** : Les tumeurs se distinguent bien dans l'espace réduit\n",
    "- **Features redondantes** : Beaucoup d'information dupliquée dans les 30 features\n",
    "- **1 dimension suffit** : LDA montre qu'on peut classifier sur 1 axe optimal\n",
    "\n",
    "### Applications pratiques :\n",
    "\n",
    "**Pour un système de diagnostic automatique** :\n",
    "1. Appliquer PCA pour réduire de 30 à 10 features\n",
    "2. Entraîner un classifieur (SVM, Random Forest, etc.)\n",
    "3. Gain : modèle plus rapide, moins de risque de surapprentissage\n",
    "\n",
    "**Pour l'exploration des données** :\n",
    "1. Utiliser t-SNE pour visualiser les groupes\n",
    "2. Identifier les outliers (tumeurs atypiques)\n",
    "3. Valider la cohérence des diagnostics\n",
    "\n",
    "### Quelle méthode choisir ?\n",
    "\n",
    "| Objectif | Méthode recommandée | Raison |\n",
    "|----------|---------------------|--------|\n",
    "| Visualisation | t-SNE | Clusters visuellement distincts |\n",
    "| Classification | LDA ou PCA(10) | Séparation optimale des classes |\n",
    "| Compression | PCA(10) | 95% variance, rapide |\n",
    "| Interprétation | PCA + Biplot | Comprendre les features importantes |\n",
    "\n",
    "### Conclusion finale :\n",
    "\n",
    "La réduction de dimensionnalité est **très pertinente** pour ce dataset car :\n",
    "- Les 30 features originales contiennent beaucoup de redondance\n",
    "- On peut conserver 95% de l'information avec seulement 10 dimensions\n",
    "- La visualisation en 2D/3D révèle une séparation claire des classes\n",
    "- Pour la classification, LDA montre qu'**une seule dimension** suffit !\n",
    "\n",
    "**Recommandation** : Utiliser PCA avec 10 composantes pour prétraiter les données avant classification, ou LDA directement si les labels sont disponibles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
