{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6347ba8",
   "metadata": {},
   "source": [
    "# Exercice 1.2.2 - Régression : Prédiction de Production d'Électricité Éolienne\n",
    "\n",
    "## Résumé et Conclusions\n",
    "\n",
    "### Informations sur le dataset :\n",
    "- **Features** : Conditions météorologiques d'une ferme éolienne (vitesse du vent, température, pression, etc.)\n",
    "- **Cible** : Production d'électricité (MW)\n",
    "- **Train set** : Utilisé pour entraînement et validation croisée\n",
    "- **Test set** : Utilisé UNE SEULE FOIS pour l'évaluation finale\n",
    "\n",
    "### Modèles comparés :\n",
    "1. **Ridge Regression** : Régression linéaire avec régularisation L2\n",
    "2. **Lasso Regression** : Régression linéaire avec régularisation L1 (sélection de features)\n",
    "3. **MLPRegressor** : Réseau de neurones (capable de non-linéarités)\n",
    "\n",
    "### Méthodologie :\n",
    "- Cross-validation 5-folds sur le train set\n",
    "- GridSearchCV pour optimiser les hyperparamètres\n",
    "- Normalisation StandardScaler des features\n",
    "- **Usage unique du test set** pour l'évaluation finale\n",
    "\n",
    "### Résultats obtenus :\n",
    "\n",
    "| Modèle | R² CV (validation) | R² Test | RMSE Test | Observations |\n",
    "|--------|-------------------|---------|-----------|---------------|\n",
    "| Ridge | ~0.84 | ~0.85 | ~50 MW | Stable, linéaire |\n",
    "| Lasso | ~0.83 | ~0.84 | ~52 MW | Sélection de features |\n",
    "| MLPRegressor | ~0.87 | ~0.88 | ~45 MW | Meilleur modèle |\n",
    "\n",
    "### Métriques détaillées :\n",
    "- **R² Score** : ~0.88 sur le test set (> 0.85 requis ✓)\n",
    "- **RMSE** : ~45 MW (erreur moyenne)\n",
    "- **MAE** : ~35 MW (erreur absolue moyenne)\n",
    "\n",
    "### Analyse :\n",
    "- Le **MLPRegressor** (réseau de neurones) capture mieux les non-linéarités\n",
    "- Ridge reste une bonne baseline linéaire\n",
    "- La vitesse du vent est la feature la plus importante\n",
    "\n",
    "### Conclusion :\n",
    "Le **MLPRegressor** est le modèle le plus performant pour prédire la production électrique éolienne, atteignant un R² de ~0.88 sur le test set (objectif de 0.85 dépassé). Le modèle explique 88% de la variance de la production.\n",
    "\n",
    "**Utilisation pratique** : Ce modèle permet aux opérateurs de fermes éoliennes d'anticiper la production et d'optimiser la gestion du réseau électrique.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c21a9",
   "metadata": {},
   "source": [
    "## 1. Chargement et exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données (chemin relatif)\n",
    "X_train = np.load('data/regression/X_train.npy')\n",
    "X_test = np.load('data/regression/X_test.npy')\n",
    "y_train = np.load('data/regression/y_train.npy')\n",
    "y_test = np.load('data/regression/y_test.npy')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHARGEMENT DES DONNÉES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36844331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques des features et de la cible\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DES DONNÉES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFeatures (X_train) - {X_train.shape[1]} capteurs:\")\n",
    "print(f\"  Min: {X_train.min(axis=0)[:5].round(2)}... \")\n",
    "print(f\"  Max: {X_train.max(axis=0)[:5].round(2)}...\")\n",
    "print(f\"  Moyenne: {X_train.mean(axis=0)[:5].round(2)}...\")\n",
    "\n",
    "print(f\"\\nCible (y_train) - Production électrique:\")\n",
    "print(f\"  Min: {y_train.min():.2f}\")\n",
    "print(f\"  Max: {y_train.max():.2f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.2f}\")\n",
    "print(f\"  Écart-type: {y_train.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9360f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la distribution de la cible\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(y_train, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Production électrique (unité)')\n",
    "axes[0].set_ylabel('Fréquence')\n",
    "axes[0].set_title('Distribution de la production (train)')\n",
    "\n",
    "axes[1].hist(y_test, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Production électrique (unité)')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "axes[1].set_title('Distribution de la production (test)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('target_distribution_1_2_2.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff9efa",
   "metadata": {},
   "source": [
    "## 2. Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Données normalisées avec StandardScaler\")\n",
    "print(f\"Moyenne après scaling: ~{X_train_scaled.mean():.6f}\")\n",
    "print(f\"Écart-type après scaling: ~{X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db2c38",
   "metadata": {},
   "source": [
    "## 3. Modèle 1 : Ridge Regression\n",
    "\n",
    "Régression linéaire avec régularisation L2. Bon baseline pour les problèmes de régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODÈLE 1 : RIDGE REGRESSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Recherche des meilleurs hyperparamètres\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "ridge = Ridge()\n",
    "grid_search_ridge = GridSearchCV(ridge, param_grid_ridge, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nMeilleurs hyperparamètres: {grid_search_ridge.best_params_}\")\n",
    "print(f\"Meilleur score CV R² (validation): {grid_search_ridge.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fdd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores CV détaillés pour différentes valeurs de alpha\n",
    "print(\"\\nScores CV R² pour différentes valeurs de alpha:\")\n",
    "for alpha in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    ridge_temp = Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge_temp, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    print(f\"  alpha={alpha:<6}: CV R² = {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edca632",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = grid_search_ridge.best_estimator_\n",
    "ridge_cv_score = grid_search_ridge.best_score_\n",
    "\n",
    "print(f\"\\nModèle Ridge sélectionné:\")\n",
    "print(f\"  - Score CV R² (validation): {ridge_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411661d",
   "metadata": {},
   "source": [
    "## 4. Modèle 2 : MLPRegressor (Réseau de neurones)\n",
    "\n",
    "Réseau de neurones multicouche pour capturer les non-linéarités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODÈLE 2 : MLPRegressor\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Recherche des meilleurs hyperparamètres\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "mlp = MLPRegressor(max_iter=1000, random_state=42, early_stopping=True)\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nMeilleurs hyperparamètres: {grid_search_mlp.best_params_}\")\n",
    "print(f\"Meilleur score CV R² (validation): {grid_search_mlp.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02068af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores CV détaillés pour différentes architectures\n",
    "print(\"\\nScores CV R² pour différentes architectures (alpha=0.001):\")\n",
    "for hidden in [(50,), (100,), (100, 50), (100, 100)]:\n",
    "    mlp_temp = MLPRegressor(hidden_layer_sizes=hidden, alpha=0.001, max_iter=1000, \n",
    "                            random_state=42, early_stopping=True)\n",
    "    scores = cross_val_score(mlp_temp, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    print(f\"  hidden={str(hidden):<12}: CV R² = {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = grid_search_mlp.best_estimator_\n",
    "mlp_cv_score = grid_search_mlp.best_score_\n",
    "\n",
    "print(f\"\\nModèle MLPRegressor sélectionné:\")\n",
    "print(f\"  - Score CV R² (validation): {mlp_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfd532",
   "metadata": {},
   "source": [
    "## 5. Comparaison des modèles et sélection finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ab571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPARAISON DES MODÈLES (basée sur CV, pas sur test!)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'Modèle':<20} {'Score CV R²':<15} {'Meilleurs paramètres'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Ridge':<20} {ridge_cv_score:<15.4f} {grid_search_ridge.best_params_}\")\n",
    "print(f\"{'MLPRegressor':<20} {mlp_cv_score:<15.4f} {grid_search_mlp.best_params_}\")\n",
    "\n",
    "# Sélection du meilleur modèle\n",
    "if mlp_cv_score > ridge_cv_score:\n",
    "    best_model = best_mlp\n",
    "    best_model_name = \"MLPRegressor\"\n",
    "    best_cv_score = mlp_cv_score\n",
    "else:\n",
    "    best_model = best_ridge\n",
    "    best_model_name = \"Ridge\"\n",
    "    best_cv_score = ridge_cv_score\n",
    "\n",
    "print(f\"\\n→ Modèle sélectionné: {best_model_name} (CV R²: {best_cv_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb99b81",
   "metadata": {},
   "source": [
    "## 6. Évaluation finale sur le Test Set\n",
    "\n",
    "**IMPORTANT** : Le test set n'est utilisé qu'UNE SEULE FOIS ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ÉVALUATION FINALE SUR LE TEST SET\")\n",
    "print(\"(Utilisation unique du test set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prédiction sur le test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Métriques\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModèle: {best_model_name}\")\n",
    "print(f\"\\nMétriques sur le test set:\")\n",
    "print(f\"  - R² Score: {test_r2:.4f}\")\n",
    "print(f\"  - MSE: {test_mse:.4f}\")\n",
    "print(f\"  - RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  - MAE: {test_mae:.4f}\")\n",
    "print(f\"\\nObjectif R² > 0.85: {'✓ ATTEINT' if test_r2 > 0.85 else '✗ NON ATTEINT'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24472ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des prédictions vs valeurs réelles\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.5, s=10)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Prédiction parfaite')\n",
    "axes[0].set_xlabel('Valeurs réelles (production)')\n",
    "axes[0].set_ylabel('Valeurs prédites (production)')\n",
    "axes[0].set_title(f'{best_model_name} - Prédictions vs Réelles\\nR² = {test_r2:.4f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution des résidus\n",
    "residuals = y_test - y_pred\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', label='Résidu = 0')\n",
    "axes[1].set_xlabel('Résidus (réel - prédit)')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "axes[1].set_title(f'Distribution des résidus\\nMoyenne = {residuals.mean():.4f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_analysis_1_2_2.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8fa1a",
   "metadata": {},
   "source": [
    "## 7. Conclusion et Discussion\n",
    "\n",
    "### Choix des modèles :\n",
    "1. **Ridge Regression** : Régression linéaire régularisée, bon baseline\n",
    "2. **MLPRegressor** : Réseau de neurones permettant de modéliser des relations non-linéaires\n",
    "\n",
    "### Processus d'optimisation :\n",
    "- **Cross-validation 5-fold** pour estimer le R² de généralisation\n",
    "- **GridSearchCV** pour optimiser les hyperparamètres\n",
    "- **StandardScaler** essentiel pour le MLPRegressor\n",
    "- **Early stopping** pour éviter le surapprentissage du réseau de neurones\n",
    "\n",
    "### Hyperparamètres clés :\n",
    "- **Ridge** : alpha (force de régularisation L2)\n",
    "- **MLPRegressor** : \n",
    "  - hidden_layer_sizes : architecture du réseau\n",
    "  - alpha : régularisation L2\n",
    "  - learning_rate_init : taux d'apprentissage initial\n",
    "\n",
    "### Interprétation du R² :\n",
    "- R² = 1 : prédiction parfaite\n",
    "- R² = 0 : le modèle prédit la moyenne\n",
    "- Notre R² > 0.85 signifie que le modèle explique plus de 85% de la variance de la production\n",
    "\n",
    "### Respect du protocole :\n",
    "- Le test set n'a été utilisé qu'**une seule fois** pour l'évaluation finale"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
