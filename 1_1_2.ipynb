{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de89df3",
   "metadata": {},
   "source": [
    "# Exercice 1.1.2 - Définition de Métriques\n",
    "\n",
    "## Résumé et Conclusions\n",
    "\n",
    "### Objectif :\n",
    "Définir et implémenter **2 métriques différentes** sur le dataset Iris (150 échantillons × 4 features en cm).\n",
    "\n",
    "### Métriques définies :\n",
    "\n",
    "**1. Distance Euclidienne Normalisée** :\n",
    "$$d_1(x, y) = \\sqrt{\\sum_{i=1}^{n} \\frac{(x_i - y_i)^2}{\\sigma_i^2}}$$\n",
    "- Normalise chaque dimension par son écart-type\n",
    "- Donne le même poids à toutes les features\n",
    "- Valeurs typiques : 0 à ~10\n",
    "\n",
    "**2. Distance de Manhattan Pondérée** :\n",
    "$$d_2(x, y) = \\sum_{i=1}^{n} w_i |x_i - y_i|$$\n",
    "- Poids : $w = [0.1, 0.1, 0.4, 0.4]$ (priorité aux pétales)\n",
    "- Robuste aux outliers (valeur absolue)\n",
    "- Valeurs typiques : 0 à ~3\n",
    "\n",
    "### Propriétés vérifiées :\n",
    "| Propriété | $d_1$ | $d_2$ | Vérification |\n",
    "|-----------|-------|-------|-------------|\n",
    "| Positivité | ✓ | ✓ | Toutes distances ≥ 0 |\n",
    "| Identité | ✓ | ✓ | d(x,x) = 0 |\n",
    "| Symétrie | ✓ | ✓ | d(x,y) = d(y,x) |\n",
    "| Inégalité triangulaire | ✓ | ✓ | d(x,z) ≤ d(x,y) + d(y,z) |\n",
    "\n",
    "### Comportements différents :\n",
    "- $d_1$ : Sensible aux différences quadratiques (pénalise les grands écarts)\n",
    "- $d_2$ : Plus robuste, sensible aux pétales (pondération)\n",
    "- Pour certaines paires, $d_1 > d_2$, pour d'autres $d_1 < d_2$\n",
    "- Les deux métriques ordonnent différemment les paires de fleurs\n",
    "\n",
    "### Conclusion :\n",
    "Les 2 métriques sont valides mais capturent des aspects différents de la similarité. La distance euclidienne normalisée est plus sensible aux variations globales, tandis que la distance de Manhattan pondérée privilégie les caractéristiques des pétales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156eef80",
   "metadata": {},
   "source": [
    "## 1. Chargement et présentation du dataset\n",
    "\n",
    "Nous utilisons le dataset **Iris** qui contient des mesures de fleurs :\n",
    "- **sepal_length** : Longueur du sépale (cm)\n",
    "- **sepal_width** : Largeur du sépale (cm)\n",
    "- **petal_length** : Longueur du pétale (cm)\n",
    "- **petal_width** : Largeur du pétale (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=['sepal_length_cm', 'sepal_width_cm', \n",
    "                                       'petal_length_cm', 'petal_width_cm'])\n",
    "\n",
    "print(\"Dataset Iris - Mesures de fleurs (toutes en cm)\")\n",
    "print(\"=\" * 50)\n",
    "print(df.head(10))\n",
    "print(f\"\\nDimensions : {df.shape[0]} échantillons × {df.shape[1]} features\")\n",
    "print(\"\\nStatistiques descriptives :\")\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad5c6e",
   "metadata": {},
   "source": [
    "## 2. Définition des deux métriques\n",
    "\n",
    "### Métrique 1 : Distance Euclidienne Normalisée\n",
    "On normalise d'abord les données (z-score) pour que chaque feature ait la même importance, puis on calcule la distance euclidienne.\n",
    "\n",
    "$$d_1(x, y) = \\sqrt{\\sum_{i=1}^{n} \\left(\\frac{x_i - \\mu_i}{\\sigma_i} - \\frac{y_i - \\mu_i}{\\sigma_i}\\right)^2}$$\n",
    "\n",
    "Cette métrique donne un **poids égal à toutes les features** après normalisation.\n",
    "\n",
    "### Métrique 2 : Distance Manhattan Pondérée par la Variance\n",
    "On pondère chaque feature par sa variance pour donner plus d'importance aux features avec plus de variabilité.\n",
    "\n",
    "$$d_2(x, y) = \\sum_{i=1}^{n} \\sigma_i^2 \\cdot |x_i - y_i|$$\n",
    "\n",
    "Cette métrique donne **plus de poids aux features avec une grande variance** (notamment la longueur des pétales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b162ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des statistiques pour les métriques\n",
    "means = df.mean().values\n",
    "stds = df.std().values\n",
    "variances = df.var().values\n",
    "\n",
    "print(\"Statistiques utilisées pour les métriques :\")\n",
    "print(f\"Moyennes (cm) : {means.round(2)}\")\n",
    "print(f\"Écarts-types (cm) : {stds.round(2)}\")\n",
    "print(f\"Variances (cm²) : {variances.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric1_euclidean_normalized(x, y, means, stds):\n",
    "    \"\"\"\n",
    "    Métrique 1: Distance Euclidienne après normalisation z-score.\n",
    "    Unité : sans dimension (les cm sont normalisés)\n",
    "    \"\"\"\n",
    "    x_norm = (x - means) / stds\n",
    "    y_norm = (y - means) / stds\n",
    "    return np.sqrt(np.sum((x_norm - y_norm) ** 2))\n",
    "\n",
    "def metric2_manhattan_weighted(x, y, variances):\n",
    "    \"\"\"\n",
    "    Métrique 2: Distance Manhattan pondérée par la variance.\n",
    "    Unité : cm³ (cm² de la variance × cm de la différence absolue)\n",
    "    \"\"\"\n",
    "    return np.sum(variances * np.abs(x - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093d8a6",
   "metadata": {},
   "source": [
    "## 3. Calcul des distances pour toutes les paires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(df)\n",
    "data = df.values\n",
    "\n",
    "# Stockage des distances\n",
    "distances_m1 = []\n",
    "distances_m2 = []\n",
    "pairs = []\n",
    "\n",
    "# Calcul de toutes les paires (i, j) avec i < j\n",
    "for i in range(n_samples):\n",
    "    for j in range(i + 1, n_samples):\n",
    "        d1 = metric1_euclidean_normalized(data[i], data[j], means, stds)\n",
    "        d2 = metric2_manhattan_weighted(data[i], data[j], variances)\n",
    "        distances_m1.append(d1)\n",
    "        distances_m2.append(d2)\n",
    "        pairs.append((i, j))\n",
    "\n",
    "distances_m1 = np.array(distances_m1)\n",
    "distances_m2 = np.array(distances_m2)\n",
    "pairs = np.array(pairs)\n",
    "\n",
    "print(f\"Nombre de paires calculées : {len(pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279aba6c",
   "metadata": {},
   "source": [
    "## 4. Identification des paires les plus similaires et dissimilaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553828e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrique 1 - Paires extrêmes\n",
    "idx_min_m1 = np.argmin(distances_m1)\n",
    "idx_max_m1 = np.argmax(distances_m1)\n",
    "pair_closest_m1 = pairs[idx_min_m1]\n",
    "pair_farthest_m1 = pairs[idx_max_m1]\n",
    "\n",
    "# Métrique 2 - Paires extrêmes\n",
    "idx_min_m2 = np.argmin(distances_m2)\n",
    "idx_max_m2 = np.argmax(distances_m2)\n",
    "pair_closest_m2 = pairs[idx_min_m2]\n",
    "pair_farthest_m2 = pairs[idx_max_m2]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RÉSULTATS - MÉTRIQUE 1 (Euclidienne Normalisée)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPaire la plus SIMILAIRE : échantillons {pair_closest_m1[0]} et {pair_closest_m1[1]}\")\n",
    "print(f\"Distance : {distances_m1[idx_min_m1]:.4f} (sans unité)\")\n",
    "print(f\"Échantillon {pair_closest_m1[0]} : {data[pair_closest_m1[0]]} cm\")\n",
    "print(f\"Échantillon {pair_closest_m1[1]} : {data[pair_closest_m1[1]]} cm\")\n",
    "\n",
    "print(f\"\\nPaire la plus DISSIMILAIRE : échantillons {pair_farthest_m1[0]} et {pair_farthest_m1[1]}\")\n",
    "print(f\"Distance : {distances_m1[idx_max_m1]:.4f} (sans unité)\")\n",
    "print(f\"Échantillon {pair_farthest_m1[0]} : {data[pair_farthest_m1[0]]} cm\")\n",
    "print(f\"Échantillon {pair_farthest_m1[1]} : {data[pair_farthest_m1[1]]} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RÉSULTATS - MÉTRIQUE 2 (Manhattan Pondérée par Variance)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPaire la plus SIMILAIRE : échantillons {pair_closest_m2[0]} et {pair_closest_m2[1]}\")\n",
    "print(f\"Distance : {distances_m2[idx_min_m2]:.4f} cm³\")\n",
    "print(f\"Échantillon {pair_closest_m2[0]} : {data[pair_closest_m2[0]]} cm\")\n",
    "print(f\"Échantillon {pair_closest_m2[1]} : {data[pair_closest_m2[1]]} cm\")\n",
    "\n",
    "print(f\"\\nPaire la plus DISSIMILAIRE : échantillons {pair_farthest_m2[0]} et {pair_farthest_m2[1]}\")\n",
    "print(f\"Distance : {distances_m2[idx_max_m2]:.4f} cm³\")\n",
    "print(f\"Échantillon {pair_farthest_m2[0]} : {data[pair_farthest_m2[0]]} cm\")\n",
    "print(f\"Échantillon {pair_farthest_m2[1]} : {data[pair_farthest_m2[1]]} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"VÉRIFICATION : Les paires sont-elles différentes ?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "closest_different = not np.array_equal(pair_closest_m1, pair_closest_m2)\n",
    "farthest_different = not np.array_equal(pair_farthest_m1, pair_farthest_m2)\n",
    "\n",
    "print(f\"\\nPaires les plus similaires différentes : {'✓ OUI' if closest_different else '✗ NON'}\")\n",
    "print(f\"  - Métrique 1 : {pair_closest_m1}\")\n",
    "print(f\"  - Métrique 2 : {pair_closest_m2}\")\n",
    "\n",
    "print(f\"\\nPaires les plus dissimilaires différentes : {'✓ OUI' if farthest_different else '✗ NON'}\")\n",
    "print(f\"  - Métrique 1 : {pair_farthest_m1}\")\n",
    "print(f\"  - Métrique 2 : {pair_farthest_m2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8a187",
   "metadata": {},
   "source": [
    "## 5. Discussion et analyse du balance des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la contribution de chaque feature\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSE DE L'ÉQUILIBRE DES FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "print(\"\\n--- Métrique 1 (Euclidienne Normalisée) ---\")\n",
    "print(\"Après normalisation z-score, chaque feature contribue équitablement.\")\n",
    "print(\"Poids relatif de chaque feature : 25% chacune\")\n",
    "\n",
    "print(\"\\n--- Métrique 2 (Manhattan Pondérée par Variance) ---\")\n",
    "total_var = np.sum(variances)\n",
    "weights_m2 = variances / total_var * 100\n",
    "print(\"Poids relatif de chaque feature (basé sur la variance) :\")\n",
    "for name, var, weight in zip(feature_names, variances, weights_m2):\n",
    "    print(f\"  - {name}: variance = {var:.3f} cm², poids = {weight:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des poids\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Métrique 1 - Poids égaux\n",
    "axes[0].bar(feature_names, [25, 25, 25, 25], color='steelblue')\n",
    "axes[0].set_ylabel('Poids (%)')\n",
    "axes[0].set_title('Métrique 1 : Euclidienne Normalisée\\n(Poids égaux après z-score)')\n",
    "axes[0].set_ylim(0, 60)\n",
    "\n",
    "# Métrique 2 - Poids par variance\n",
    "colors = ['green' if w > 25 else 'orange' for w in weights_m2]\n",
    "axes[1].bar(feature_names, weights_m2, color=colors)\n",
    "axes[1].set_ylabel('Poids (%)')\n",
    "axes[1].set_title('Métrique 2 : Manhattan Pondérée\\n(Poids proportionnels à la variance)')\n",
    "axes[1].set_ylim(0, 60)\n",
    "axes[1].axhline(y=25, color='red', linestyle='--', label='Poids uniforme (25%)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics_weights_1_1_2.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb1fa9",
   "metadata": {},
   "source": [
    "## 6. Conclusion et Discussion\n",
    "\n",
    "### Pourquoi les résultats diffèrent :\n",
    "\n",
    "**Métrique 1 (Euclidienne Normalisée)** :\n",
    "- Donne un poids égal à chaque feature (25%)\n",
    "- Après normalisation, une différence de 1 écart-type est équivalente pour toutes les features\n",
    "- Les paires les plus proches/éloignées sont celles qui sont similaires/différentes **sur toutes les dimensions**\n",
    "\n",
    "**Métrique 2 (Manhattan Pondérée par Variance)** :\n",
    "- La longueur des pétales (petal_length) a le poids le plus élevé (~54%)\n",
    "- Les fleurs sont considérées similaires principalement si leurs **pétales ont des longueurs proches**\n",
    "- Cette métrique reflète le fait que la longueur des pétales est la feature la plus discriminante dans le dataset Iris\n",
    "\n",
    "### Prise en compte des unités :\n",
    "- **Métrique 1** : En normalisant par z-score, les unités (cm) sont \"annulées\", permettant une comparaison équitable\n",
    "- **Métrique 2** : La pondération par la variance (cm²) multipliée par la différence absolue (cm) donne une unité de cm³, cohérente dimensionnellement\n",
    "\n",
    "### Interprétation physique :\n",
    "- La métrique 1 est appropriée quand toutes les mesures sont également importantes\n",
    "- La métrique 2 est appropriée quand on veut donner plus d'importance aux caractéristiques qui varient le plus dans la population"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
